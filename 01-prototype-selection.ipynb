{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Protótipos\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Motivação](#motivação)\n",
    "2. [Edited Nearest Neighbors](#edited-nearest-neighbors)\n",
    "3. [Instance Hardness Threshold](#instance-hardness-threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivação\n",
    "\n",
    "Seleção de protótipos refere-se ao ato de remover instâncias do _dataset_. A remoção controlada tem como objetivo melhorar o dataset inicial, criando uma região de separação mais clara entre as classes ou para resolver problemas inerentes dos classificadores. Vamos observar o _kNN_ como exemplo, podemos citar algumas falhas do algoritmo:\n",
    "\n",
    "- computa a distância da instância de teste para todas as instâncias de treino, se a quantidade de amostras for muito grande, o algoritmo demora mais tempo\n",
    "- ao observar a região de vizinhança de uma amostra que se encontra na região de separação de duas classes, não havendo uma clara predominância de uma das classes, qualquer variação pode levar a uma mudança na classificação, sendo menos resiliente à ruídos.\n",
    "\n",
    "O problema do ruído pode ser mitigado por aumentar o valor de $k$, escolhido durante o processo de otimização do modelo. Entretanto, a melhor solução pode ser um valor pequeno de $k$, e é apenas necessária uma pequena melhora nos limites de decisão do algoritmo.\n",
    "\n",
    "Para isso, utilizamos métodos de seleção de protótipo. Os algoritmos de seleção de protótipo não estão disponíveis no _sklearn_. Entretanto, existem bibliotecas que implementam esses algoritmos, como o [_imbalanced-learn_](https://imbalanced-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors\n",
    "\n",
    "Vamos estudar o _Edited Nearest Neighbors_ (ENN), aqui a regra é remover as instâncias que são classificadas erroneamente por um classificador _kNN_. Esse método preza por remover instâncias que estão próximas da região de decisão.\n",
    "\n",
    "Vamos estudar esse efeito no problema de classificação de vinhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caso o código não execute, descomente a linha abaixo e execute essa célula\n",
    "# ! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipualção e visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# vamos definir cores e simbolos para nossas classses\n",
    "colors = {0: \"steelblue\", 1: \"darkorange\", 2: \"mediumseagreen\"}\n",
    "markers = {0: \"s\", 1: \"^\", 2:\"o\"}\n",
    "\n",
    "# vamos criar uma função para visualizar uma região 2d, dadas duas features\n",
    "def plot_2d_space(X, y, f1, f2, colors=colors, markers=markers):\n",
    "    plt.figure()\n",
    "    labels = list(y.unique())\n",
    "    labels.sort()\n",
    "\n",
    "    lines = []\n",
    "    for i in labels:\n",
    "        line = plt.scatter(\n",
    "            X[f1][y==i],\n",
    "            X[f2][y==i], \n",
    "            c=colors[i], \n",
    "            marker=markers[i],\n",
    "            label=i,\n",
    "        )\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "    plt.legend(handles=lines)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar nosso dataset\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Função para separação dos dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# vamos carregar o dataset\n",
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "# como duas classes estão distribuidas por duas features?\n",
    "feature_0 = \"alcohol\"\n",
    "feature_1 = \"color_intensity\"\n",
    "\n",
    "# dividindo em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, shuffle=True, random_state=199)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que na região central, todas as classes meio que se misturam. Como vimos, essa mistura pode ser prejudicial para o _kNN_. Vamos avalia-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# vamos observar cada uma das classes usando duas features..\n",
    "plot_2d_space(X_train, y_train, feature_0, feature_1)\n",
    "\n",
    "print(classification_report(y_test, classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ver o resultado com o ENN.\n",
    "\n",
    "Aqui temos alguns hiperparâmetros para controlar:\n",
    "\n",
    "- _n_neighbors_: tamanho da vizinhança\n",
    "- _sampling_strategy_: escolha das classes que serão removidas, pode assumir o valor de lista para as classes da lista serem removidas, ou um dos seguintes:\n",
    "    * _\"majority\"_: remove apenas da classe majoritaria\n",
    "    * _\"not majority\"_: remove de todas as classes menos da majoritaria\n",
    "    * _\"not minority\"_: remove de todas as classes menos da minoritaria\n",
    "    * _\"all\"_: remove de todas as classes\n",
    "    * _\"auto\"_: equivalente à _\"not minority\"_\n",
    "- _kind_sel_: estratégia usada para remoção:\n",
    "    * _\"all\"_: todos os vizinhos terão que concordar com as amostras de interesse para não serem excluídos\n",
    "    * _\"mode\"_: utiliza voto majoritário para excluir uma amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "resampler = EditedNearestNeighbours(n_neighbors=5, sampling_strategy=\"auto\", kind_sel=\"mode\")\n",
    "X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# e as classes filtradas usando ENN\n",
    "plot_2d_space(X_train_resampled, y_train_resampled, feature_0, feature_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui percebemos que várias amostras das classes majoritárias próximas da região de separação foram removidas. Como amostras da classe minoritária não foram removidas (classe 2). Portanto, como está mais fácil classificar essa classe específica, devemos observar uma melhora na classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos uma melhora na classificação das classes 1 e 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Hardness Threshold\n",
    "\n",
    "Esse algoritmo remove instâncias que sejam dificeis de serem classificadas. Para medir a dificuldade de classificação de uma instância, é utilizado um classificador para nos auxiliar. Esse classificador avalia a probabilidade daquela instãncia ser classificada, as instâncias com maior probabilidade de serem classificadas são mantidas, as instâncias com menor probabilidade são removidas.\n",
    "\n",
    "Como hiperparâmetros, temos:\n",
    "\n",
    "- _estimator_: o classificador utilizado para auferir a probabilidade de cada instância. Como padrão o _RandomForestClassifier_ é utilizado, e 'knn', 'decision-tree', 'random-forest', 'adaboost', 'gradient-boosting' and 'linear-svm' como opções.\n",
    "- _sampling_strategy_: aqui temos uma variedade de possibilidades:\n",
    "    * _float_: caso seja passado um _float_, o numero corresponde à razão do número de amostras da classe minoritária em relação à classe majoritária após reamostragem.\n",
    "    * _str_: semelhante ao ENN.\n",
    "    * _dict_: um dicionário corresponderá à quantidade de amostras por classe, no formato {_classe_: _numero_de_amostras_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "resampler = InstanceHardnessThreshold(random_state=199)\n",
    "X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# e as classes filtradas usando ENN\n",
    "plot_2d_space(X_train_resampled, y_train_resampled, feature_0, feature_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que apesar de uma região completamente diferente no treinamento do _kNN_, o resultado no teste se manteve."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2740ff0ff5ab647f4caa51cae9634c8f0b586b6f57486f90b97d87d738fcb59"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('mscenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
